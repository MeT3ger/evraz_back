{"ml-flask-api-master": {}, ".github": {}, "ISSUE_TEMPLATE": {}, "bug_report.md": "---\nname: Bug report\nabout: Create a report to help us improve\ntitle: \"[BUG] \"\nlabels: bug\nassignees: ''\n\n---\n\n**Describe the bug**\nA clear and concise description of what the bug is.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Desktop (please complete the following information):**\n - OS: [e.g. iOS]\n - Browser [e.g. chrome, safari]\n - Version [e.g. 22]\n\n**Additional context**\nAdd any other context about the problem here.\n", "feature_request.md": "---\nname: Feature request\nabout: Suggest an idea for this project\ntitle: \"[FEATURE] \"\nlabels: enhancement\nassignees: ''\n\n---\n\n**Is your feature request related to a problem? Please describe.**\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n", "docker": {}, ".env": "MODEL_NAME=model.joblib\nMODEL_TYPE=SKLEARN_MODEL\n", "Dockerfile": "FROM python:3\n\nWORKDIR /app\n\nRUN pip install --upgrade pip\n\n# Copy and install service requirements\nCOPY requirements-service.txt .\nRUN pip install -r ./requirements-service.txt\n\n# Copy model requirements\nCOPY requirements.txt .\nRUN pip install -r ./requirements.txt\n\n# Copy code and model\nCOPY . .\n\nEXPOSE 5000\n\nCMD gunicorn -b 0.0.0.0:5000 service --timeout 300 --workers=2 --threads=4 --worker-class=gthread\n\n", "docsrc": {}, "make.bat": "@ECHO OFF\n\npushd %~dp0\n\nREM Command file for Sphinx documentation\n\nif \"%SPHINXBUILD%\" == \"\" (\n\tset SPHINXBUILD=sphinx-build\n)\nset SOURCEDIR=source\nset BUILDDIR=_build\n\nif \"%1\" == \"\" goto help\nif \"%1\" == \"github\" goto github\n\n%SPHINXBUILD% >NUL 2>NUL\nif errorlevel 9009 (\n\techo.\n\techo.The 'sphinx-build' command was not found. Make sure you have Sphinx\n\techo.installed, then set the SPHINXBUILD environment variable to point\n\techo.to the full path of the 'sphinx-build' executable. Alternatively you\n\techo.may add the Sphinx directory to PATH.\n\techo.\n\techo.If you don't have Sphinx installed, grab it from\n\techo.http://sphinx-doc.org/\n\texit /b 1\n)\n\n%SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\ngoto end\n\n:help\n%SPHINXBUILD% -M help %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\n\n:github\n%SPHINXBUILD% -M html %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\nxcopy /s %BUILDDIR%\\html ..\\docs\ngoto end\n\n:end\npopd\n", "Makefile": "# Minimal makefile for Sphinx documentation\n#\n\n# You can set these variables from the command line.\nSPHINXOPTS    =\nSPHINXBUILD   = sphinx-build\nSOURCEDIR     = source\nBUILDDIR      = _build\n\n# Put it first so that \"make\" without argument is like \"make help\".\nhelp:\n\t@$(SPHINXBUILD) -M help \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)\n\n.PHONY: help Makefile\n\n# Catch-all target: route all unknown targets to Sphinx using the new\n# \"make mode\" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).\n%: Makefile\n\t@$(SPHINXBUILD) -M $@ \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)\n\ngithub:\n\t@make html\n\t@cp -a \"$(BUILDDIR)/html/.\" ../docs\n", "source": {}, "base_model.rst": "Base Model\n~~~~~~~~~~\n.. automodule:: python.model.base\n  :members:\n  :undoc-members:\n  :show-inheritance:\n  :exclude-members: SHAP_AVAILABLE, Task\n", "code_doc.rst": "Code Documentation\n==================\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n   base_model\n   sklearn_model\n   service_api\n", "conf.py": "# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('../..'))\nsys.setrecursionlimit(1500)\n\n\n# -- Project information -----------------------------------------------------\n\nproject = 'ML Model Deployment'\ncopyright = '2019, lopezco'\nauthor = 'lopezco'\n\n# The short X.Y version\nversion = '2.2.0'\n# The full version, including alpha/beta/rc tags\nrelease = '2.2.0'\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.intersphinx',\n    'sphinx.ext.todo',\n    'sphinx.ext.coverage',\n    'sphinx.ext.ifconfig',\n    'sphinx.ext.viewcode',\n    'sphinx.ext.githubpages',\n    'sphinx.ext.napoleon',\n    'm2r'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = 'sphinx_rtd_theme'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n#html_static_path = ['_static']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don't match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',\n# 'searchbox.html']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'ml-flask-api-doc'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',\n\n    # Latex figure (float) alignment\n    #\n    # 'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, 'ml-flask-api.tex', 'ml-flask-api Documentation',\n     'lopezco', 'manual'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'ml-flask-api', 'ml-flask-api Documentation',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'ml-flask-api', 'ml-flask-api Documentation',\n     author, 'ml-flask-api', 'One line description of project.',\n     'Miscellaneous'),\n]\n\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = ''\n\n# A unique identification for the text.\n#\n# epub_uid = ''\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = ['search.html']\n\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for intersphinx extension ---------------------------------------\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {'https://docs.python.org/': None}\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n", "index.rst": "Machine Learning Model deployment\n=================================\n\n.. toctree::\n   :maxdepth: 3\n   :caption: Contents\n\n   readme\n   code_doc\n", "readme.rst": ".. mdinclude:: ../../README.md\n", "service_api.rst": "\nService\n-------\n.. automodule:: service\n  :members:\n  :undoc-members:\n  :show-inheritance:\n  :exclude-members: MODEL_TYPE, DEBUG, MODEL_NAME, ENVIRONMENT, SERVICE_START_TIMESTAMP, app, model\n", "sklearn_model.rst": "Scikit-learn Model\n~~~~~~~~~~~~~~~~~~\n.. automodule:: python.model.sklearn\n  :members:\n  :undoc-members:\n  :show-inheritance:\n", "src": {}, "factory.py": "import os\nfrom .model import SklearnModel\n\n\nclass ModelFactory(object):\n    available_models = (SklearnModel, )\n\n    @classmethod\n    def create_model(cls, model_name, model_type='SKLEARN_MODEL'):\n        # Get current directory\n        base_dir = os.getcwd()\n        # Fix for documentation compilation\n        if os.path.basename(base_dir) == 'docsrc':\n            base_dir = os.path.dirname(base_dir)\n        # Check if there is a model in the directory with the expected name\n        model_path = os.path.join(base_dir, model_name)\n        if not os.path.exists(model_path):\n            raise RuntimeError(\"Model {} not found\".format(model_path))\n        else:\n            # Model found! now create an instance\n            for model_class in cls.available_models:\n                if model_class.family == model_type:\n                    return model_class(model_path)\n", "__init__.py": "", "model": {}, "base.py": "import numpy as np\nimport pandas as pd\n\nfrom pandas.api.types import CategoricalDtype\nfrom threading import Thread\nfrom copy import deepcopy\nfrom functools import wraps\n\n\ntry:\n    import shap\nexcept ImportError:\n    SHAP_AVAILABLE = False\nelse:\n    SHAP_AVAILABLE = True\n\n\ndef _check(ready=True, explainable=False, task=None):\n    def actual_decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            self = args[0]\n            # Check rediness\n            if ready and not self.is_ready():\n                raise RuntimeError('Model is not ready yet.')\n            # Check explainable\n            if explainable and not self._is_explainable:\n                model_name = type(self._model).__name__\n                raise ValueError('Model not supported for explanations: {}'.format(model_name))\n            # Check for task\n            if task is not None:\n                self_task = self.task_type()\n                if not getattr(self_task, '__ge__' if task.upper() == 'CLASSIFICATION' else '__eq__')(Task(task)):\n                    raise RuntimeError('This method is not available for {} tasks'.format(self_task.name.lower()))\n            # Execute function\n            return func(*args, **kwargs)\n        return wrapper\n    return actual_decorator\n\n\nclass Task(int):\n    _REGRESSION, _CLASSIFICATION = 0, 1\n    _BINARY_CLASSIFICATION, _MULTILABEL_CLASSIFICATION = 2, 3\n\n    def __new__(cls, name):\n        assert(isinstance(name, str))\n        try:\n            val = getattr(cls, '_{}'.format(name.upper()))\n        except AttributeError:\n            raise AttributeError('Unknown task-name: {}'.format(name))\n        else:\n            return  super(Task, cls).__new__(cls, val)\n\n    def __init__(self, name):\n        self.name = name.upper()\n        self._id = int(self)\n\n    def __repr__(self):\n        return \"Task('{}')\".format(self.name)\n\n# TODO: \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u0442\u044c \u0447\u0435\u0440\u0435\u0437 Abstract Base Classes\n# TODO: \u0422\u0438\u043f\u0438\u0437\u0430\u0446\u0438\u044f\nclass BaseModel(object):\n    \"\"\"Abstract class that handles the loaded model.\"\"\"\n    family = ''\n    # Explainable models\n    _explainable_models = tuple()\n\n    def __init__(self, file_name):\n        self._file_name = file_name\n        self._is_ready = False\n        self._model = None\n        self._metadata = None\n        self._task_type = None\n        self._is_explainable = False\n\n    # Abstract\n    def _load(self):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check()\n    def _get_predictor(self):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check(task='classification')\n    def _get_class_names(self):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check()\n    def preprocess(self, features):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check()\n    def predict(self, features):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check(task='classification')\n    def predict_proba(self, features):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    @_check(explainable=True)\n    def explain(self, features, samples=None):\n        \"\"\"Abstract method\"\"\"\n        raise NotImplementedError()\n\n    # Private\n    def _get_predictor_type(self):\n        return str(type(self._get_predictor()))\n\n    def _hydrate(self, model, metadata):\n        # Fill attributes\n        self._model = model\n        self._metadata = metadata\n        self._is_ready = True\n        # Hydrate class\n        clf = self._get_predictor()\n        # SHAP\n        model_name = type(clf).__name__\n        self._is_explainable = SHAP_AVAILABLE and (model_name in self._explainable_models)\n        # Feature importances\n        if hasattr(clf, 'feature_importances_'):\n            importance = clf.feature_importances_\n            for imp, feat in zip(importance, metadata['features']):\n                feat['importance'] = imp\n        # Set model task type\n        if not hasattr(clf, 'classes_'):\n            self._task_type = Task('REGRESSION')\n        elif len(clf.classes_) <= 2:\n            self._task_type = Task('BINARY_CLASSIFICATION')\n        elif len(clf.classes_) > 2:\n            self._task_type = Task('MULTILABEL_CLASSIFICATION')\n\n    @_check()\n    def _feature_names(self):\n        return [variable['name'] for variable in self.features()]\n\n    @_check()\n    def _validate(self, input):\n        if self.metadata.get('features') is None:\n            raise AttributeError(\"Missing key 'features' in model's metadata\")\n\n        # Ensure input is lislike shaped\n        input = self._get_list_from(input)\n        # Get feature names in order\n        feature_names = [f['name'] for f in self.metadata['features']]\n        # Create an index to handle multiple samples input\n        index = list(range(len(input)))\n        # Create DataFrame\n        df = pd.DataFrame(input, index=index, columns=feature_names)\n        # Convert features to expected types\n        for feature in self.metadata['features']:\n            name, var_type = feature['name'], feature['type']\n            default = feature.get('default', None)\n            categories = feature.get('categories', None)\n            accepts_missing = feature.get('accepts_missing', True)\n            if name not in df.columns:\n                df[name] = default or np.nan\n            else:\n                has_missing = df[name].isnull().any()\n                if has_missing and not accepts_missing:\n                    raise ValueError(f'Feature {name} has unexpected missing values')\n                if var_type == 'numeric':\n                    var_type = float\n                elif var_type == 'string':\n                    var_type = str\n                elif var_type == 'category':\n                    if categories is not None:\n                        var_type = CategoricalDtype(categories=categories, ordered=True)\n                        new_cat = set(df[name].dropna().unique()).difference(categories)\n                        if len(new_cat):\n                            raise ValueError(f'Unexpected categorical value for {name}: {new_cat}')\n                    else:\n                        raise ValueError(f'Missing \"categories\" for \"{name}\" in metadata')\n                else:\n                    raise ValueError(f'Unknown variable type: {var_type}')\n\n                if default is None:\n                    df[name] = df[name].astype(var_type)\n                else:\n                    df[name] = df[name].fillna(default).astype(var_type)\n            # TO DO: add more validation logic\n        return df\n\n    @property\n    @_check()\n    def _is_classification(self):\n        return self._task_type >= Task('CLASSIFICATION')\n\n    @property\n    @_check()\n    def _is_binary_classification(self):\n        return self._task_type == Task('BINARY_CLASSIFICATION')\n\n    @property\n    @_check()\n    def _is_multilabel_classification(self):\n        return self._task_type == Task('MULTILABEL_CLASSIFICATION')\n\n    @property\n    @_check()\n    def _is_regression(self):\n        return self._task_type == Task('REGRESSION')\n\n    # Private (static)\n    @staticmethod\n    def _get_list_from(data):\n        if isinstance(data, dict):\n            return [data]\n        elif pd.api.types.is_list_like(data):\n            return data\n        else:\n            return [data]\n\n    # Public\n    def load(self):\n        \"\"\"Launch model loading in a separated thread\n\n        Once it finishes, the instance `_is_ready` parameter is set to `True`.\n\n        The loaded object is expected to be a :class:`dict` containing the\n        following keys: `model` (model object) and `metadata` (:class:`dict`).\n        The later contains one or two elements: `features`\n        (:class:`list` of :class:`dict`) with at least the `name` and `type` of\n        the variables and optional `class_names` (:class:`list` of :class:`str`)\n        with the list of class-names in order (for classification).\n        \"\"\"\n        Thread(target=self._load).start()\n\n    def is_ready(self):\n        \"\"\"Check if model is already loaded.\n\n        Returns:\n            bool:\n                Is the model already loaded and ready for predictions?\n        \"\"\"\n        return self._is_ready\n\n    @property\n    @_check()\n    def metadata(self):\n        \"\"\"Get metadata of the model_name.\n\n        Returns:\n            dict:\n                Metadata of the model containing information about the features\n                and classes (optional)\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        return self._metadata\n\n    @_check()\n    def task_type(self, as_text=False):\n        \"\"\"Get task type of the model\n\n        Either 'REGRESSION', 'CLASSIFICATION', 'BINARY_CLASSIFICATION' or\n        'MULTILABEL_CLASSIFICATION'.\n\n        Returns:\n            :class:`Task` or :class:`str`:\n                If `as_text=False`, returns the task of the model\n                (classification, regression, etc.) as a :class:`Task` class\n                instance. If `as_text=True`, returns the task of the model as\n                text.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        return self._task_type.name if as_text else self._task_type\n\n    @_check()\n    def features(self):\n        \"\"\"Get the features of the model\n\n        The returned list contains records. Each record contais (at least)\n        the `name` and `type` of the variable. If the model supports\n        feature importances calculation (if the clasifier has\n        `feature_importances_` atribute), they will also be present.\n\n        Returns:\n            list[dict]:\n                Model features.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        return deepcopy(self.metadata['features'])\n\n    @property\n    @_check()\n    def info(self):\n        \"\"\"Get model information.\n\n        This function gives complete description of the model.\n        The returned ibject contais the following keys:\n\n            metadata (:class:`dict`): Model metadata (see :func:`~src.model.base.BaseModel.metadata`).\n\n            model (:class:`dict`): Context information of the learnt model.\n                type (:class:`str`):\n                    Type of the underlying model object.\n                predictor_type (:class:`str`):\n                    It could be the same as 'type'. However, for\n                    `sklearn.pipeline.Pipeline <https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html>`_\n                    it will output the class of the predictor inside it.\n                is_explainable (:class:`bool`):\n                    `True` if the model class allows SHAP explanations to be\n                    computed.\n                task (:class:`str`):\n                    Task type. Either 'BINARY_CLASSIFICATION',\n                    'MULTILABEL_CLASSIFICATION' or 'REGRESSION'\n                class_names (:class:`list` or :class:`None`):\n                    Class names if defined (for classification only).\n\n        Returns:\n            dict:\n                Information about the model.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        result = {}\n        # Metadata\n        result['metadata'] = self._metadata\n        # Info from model\n        result['model'] = {\n            'type': str(type(self._model)),\n            'predictor_type': self._get_predictor_type(),\n            'is_explainable': self._is_explainable,\n            'task': self.task_type(as_text=True),\n            'family': self.family\n        }\n        if self._is_classification:\n            result['model']['class_names'] = self._get_class_names()\n        return result\n", "sklearn.py": "import joblib\nimport numpy as np\nimport pandas as pd\n\nfrom .base import BaseModel, _check\n\ntry:\n    import shap\nexcept ImportError:\n    pass\n\n\nclass SklearnModel(BaseModel):\n    \"\"\"Class that handles the loaded model.\n\n    This class can handle models that respect the scikit-learn API. This\n    includes `sklearn.pipeline.Pipeline <https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html>`_.\n\n    The data coming from a request if validated using the metadata setored with\n    the model. The data fed to the `predict`, `predict_proba`, `explain` handle\n    `preprocess` should be a dictionary that object must contain one key per\n    feature or a list of such dictionaries (recors).\n    Example: `{'feature1': 5, 'feature2': 'A', 'feature3': 10}`\n\n    Args:\n        file_name (str):\n            File path of the serialized model. It must be a file that can be\n            loaded using :mod:`joblib`\n    \"\"\"\n    family = 'SKLEARN_MODEL'\n\n    # Explainable models\n    _explainable_models = (\n        # Sklearn\n        'DecisionTreeClassifier', 'DecisionTreeRegressor',\n        'RandomForestClassifier', 'RandomForestRegressor',\n        # XGBoost\n        'XGBClassifier', 'XGBRegressor', 'Booster',\n        # CatBoost\n        'CatBoostClassifier', 'CatBoostRegressor',\n        # LightGBM\n        'LGBMClassifier', 'LGBMRegressor')\n\n    # Private\n    def _load(self):\n        # Load serialized model (dict expected)\n        loaded = joblib.load(self._file_name)\n        self._hydrate(loaded['model'], loaded['metadata'])\n\n    @_check()\n    def _get_predictor(self):\n        return SklearnModel._extract_base_predictor(self._model)\n\n    @_check(task='classification')\n    def _get_class_names(self):\n        return np.array(self._get_predictor().classes_, str)\n\n    # Private (static)\n    @staticmethod\n    def _extract_base_predictor(model):\n        model_name = type(model).__name__\n        if model_name == 'Pipeline':\n            return SklearnModel._extract_base_predictor(model.steps[-1][1])\n        elif 'CalibratedClassifier' in model_name:\n            return SklearnModel._extract_base_predictor(model.base_estimator)\n        else:\n            return model\n\n    # Public\n    @_check()\n    def preprocess(self, features):\n        \"\"\"Preprocess data\n\n        This function is used before prediction or interpretation.\n\n        Args:\n            features (dict):\n                The expected object must contain one key per feature.\n                Example: `{'feature1': 5, 'feature2': 'A', 'feature3': 10}`\n\n        Returns:\n            dict:\n                Processed data if a preprocessing function was definded in the\n                model's metadata. The format must be the same as the input.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        input = self._validate(features)\n        if hasattr(self._model, 'transform'):\n            return self._model.transform(input)\n        else:\n            return input\n\n    @_check()\n    def predict(self, features):\n        \"\"\"Make a prediciton\n\n        Prediction function that returns the predicted class. The returned value\n        is an integer when the class names are not expecified in the model's\n        metadata.\n\n        Args:\n            features (dict):\n                Record to be used as input data to make predictions. The\n                expected object must contain one key per feature.\n                Example: `{'feature1': 5, 'feature2': 'A', 'feature3': 10}`\n\n        Returns:\n            int or str:\n                Predicted class.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n        \"\"\"\n        input = self._validate(features)\n        result = self._model.predict(input)\n        return result\n\n    @_check(task='classification')\n    def predict_proba(self, features):\n        \"\"\"Make a prediciton\n\n        Prediction function that returns the probability of the predicted\n        classes. The returned object contais one value per class. The keys of\n        the dictionary are the classes of the model.\n\n        Args:\n            features (dict): Record to be used as input data to make\n                predictions. The expected object must contain one key per\n                feature. Example:\n                {'feature1': 5, 'feature2': 'A', 'feature3': 10}\n\n        Returns:\n            dict: Predicted class probabilities.\n\n        Raises:\n            RuntimeError: If the model isn't ready or the task isn't classification.\n        \"\"\"\n        input = self._validate(features)\n        prediction = self._model.predict_proba(input)\n        df = pd.DataFrame(prediction, columns=self._get_class_names())\n        return df.to_dict(orient='records')\n\n    @_check(explainable=True)\n    def explain(self, features, samples=None):\n        \"\"\"Explain the prediction of a model.\n\n        Explanation function that returns the SHAP value for each feture.\n        The returned object contais one value per feature of the model.\n\n        If `samples` is not given, then the explanations are the raw output of\n        the trees, which varies by model (for binary classification in XGBoost\n        this is the log odds ratio). On the contrary, if `sample` is given,\n        then the explanations are the output of the model transformed into\n        probability space (note that this means the SHAP values now sum to the\n        probability output of the model).\n        See the `SHAP documentation <https://shap.readthedocs.io/en/latest/#shap.TreeExplainer>`_ for details.\n\n        Args:\n            features (dict): Record to be used as input data to explain the\n                model. The expected object must contain one key per\n                feature. Example:\n                {'feature1': 5, 'feature2': 'A', 'feature3': 10}\n            samples (dict): Records to be used as a sample pool for the\n                explanations. It must have the same structure as `features`\n                parameter. According to SHAP documentation, anywhere from 100\n                to 1000 random background samples are good sizes to use.\n        Returns:\n            dict: Explanations.\n\n        Raises:\n            RuntimeError: If the model is not ready.\n            ValueError: If the model' predictor doesn't support SHAP\n                explanations or the model is not already loaded.\n                Or if the explainer outputs an unknown object\n        \"\"\"\n        # Process input\n        preprocessed = self.preprocess(features)\n        # Define parameters\n        if samples is None:\n            params = {\n                'feature_dependence': 'tree_path_dependent',\n                'model_output': 'margin'}\n        else:\n            params = {\n                'data': self.preprocess(self._validate(samples)),\n                'feature_dependence': 'independent',\n                'model_output': 'probability'}\n        # Explainer\n        explainer = shap.TreeExplainer(self._get_predictor(), **params)\n        colnames = self._feature_names()\n        # This patch will ensure that the data will be fed as a pandas DataFrame\n        # instead of as a numpy array to some models. Ex: LightGBM\n        input_data = preprocessed[colnames]\n        predictor_type = self._get_predictor_type()\n        use_pandas = any(c in predictor_type for c in ('LGBMClassifier', 'LGBMRegressor'))\n        shap_values = explainer.shap_values(input_data if use_pandas else input_data.values)\n\n        # Create an index to handle multiple samples input\n        index = preprocessed.index\n        result = {}\n        if self._is_classification:\n            class_names = self._get_class_names()\n            if isinstance(shap_values, list):\n                # The result is one set of explanations per target class\n                process_shap_values = False\n            elif isinstance(shap_values, np.ndarray) and self._is_binary_classification:\n                # The result is one ndarray set of explanations for one class\n                # Expected only for binary classification for some models.\n                # Ex: LGBMClassifier\n                process_shap_values = True\n            else:\n                raise ValueError('Unknown objet class for shap_values variable')\n            # Format output\n            for i, c in enumerate(class_names):\n                if process_shap_values:\n                    _values = shap_values * (-1 if i == 0 else 1)\n                else:\n                    _values = shap_values[i]\n                result[c] = pd.DataFrame(_values, index=index,\n                                         columns=colnames).to_dict(orient='records')\n        else:  # self._is_regression\n            result = pd.DataFrame(shap_values, index=index,\n                                  columns=colnames).to_dict(orient='records')\n        return result\n", "utils": {}, "encoder.py": "import flask\nimport json\nimport numpy as np\nimport pandas as pd\n\nfrom functools import wraps\n\n\nclass ExtendedEncoder(flask.json.JSONEncoder):\n    \"\"\"Encoder of numpy primitives and Pandas objects into JSON strings\"\"\"\n    primitives = (np.ndarray, np.integer, np.inexact)\n\n    def default(self, obj):\n        if isinstance(obj, np.flexible):\n            return None if isinstance(obj, np.void) else obj.tolist()\n        elif isinstance(obj, self.primitives):\n            return obj.tolist()\n        elif isinstance(obj, pd.DataFrame):\n            return obj.to_dict('records')\n        elif isinstance(obj, pd.Series):\n            return json.JSONEncoder.default(self, obj.to_frame())\n        return json.JSONEncoder.default(self, obj)\n\n# TODO: \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043d\u0435 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0432\u0443\u0435\u0442 pep\ndef returns_json(f):\n    \"\"\"Wraps a function to transform the output into a JSON string with a\n    specific encoder\"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        r = f(*args, **kwargs)\n        if isinstance(r, flask.Response):\n            return r\n        else:\n            return flask.Response(json.dumps(r, cls=ExtendedEncoder), status=200,\n                                  mimetype='application/json; charset=utf-8')\n    return decorated_function\n", "helper_functions.py": "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n\n\ndef metadata_from_dataframe(df):\n    \"\"\"Build metadata from a dataset\n\n    Args:\n        df (:class:`pandas.DataFrame`):\n            File path of the serialized model. It must be a file that can be\n            loaded using :mod:`joblib`\n\n    Returns:\n        dict:\n            Information about the variables of the dataset.\n\n    Raises:\n        ValueError: If a type of variable is not handled by this function\n    \"\"\"\n    metadata = []\n    for c in df.columns:\n        if is_categorical_dtype(df[c]):\n            tmp = {'name': c,\n                   'type': 'category',\n                   'categories': sorted(df[c].dtype.categories.values.tolist())}\n        elif is_numeric_dtype(df[c]):\n            tmp = {'name': c, 'type': 'numeric'}\n        elif is_string_dtype(df[c]):\n            tmp = {'name': c, 'type': 'string'}\n        else:\n            raise ValueError('Unknown type for {}'.format(c))\n        tmp['accepts_missing'] = df[c].isnull().any()\n        metadata.append(tmp)\n    return metadata\n", "tests": {}, "tests.postman_collection.json": "{\n\t\"info\": {\n\t\t\"_postman_id\": \"895f0fd4-9169-42d3-a035-e944b1419a83\",\n\t\t\"name\": \"Test API Flask ML\",\n\t\t\"schema\": \"https://schema.getpostman.com/json/collection/v2.1.0/collection.json\"\n\t},\n\t\"item\": [\n\t\t{\n\t\t\t\"name\": \"GET\",\n\t\t\t\"item\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Model information\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"deaf461b-b5ef-4a90-9dbb-88f39857a58c\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"GET\",\n\t\t\t\t\t\t\"header\": [],\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/info\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"info\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Service information\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"ed78c9f6-11f7-407f-a80e-139b042bccfd\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"GET\",\n\t\t\t\t\t\t\"header\": [],\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/service-info\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"service-info\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Features\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"42f4bf71-1b63-4d76-a157-24839fa09086\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"GET\",\n\t\t\t\t\t\t\"header\": [],\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/features\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"features\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Health check\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"f119943d-61aa-4030-b223-9b003ac7087f\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\",\n\t\t\t\t\t\t\t\t\t\"\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"GET\",\n\t\t\t\t\t\t\"header\": [],\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/health\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"health\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Ready (model loaded)\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"8dd2aa0d-80fa-4c29-9a7d-2c1f93c882eb\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"GET\",\n\t\t\t\t\t\t\"header\": [],\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/ready\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"ready\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"name\": \"POST\",\n\t\t\t\"item\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Predict & Explain (Example)\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"720f502e-25b7-466e-952c-1320eb1ab1fb\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\",\n\t\t\t\t\t\t\t\t\t\"\",\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Content-Type is present\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.header(\\\"Content-Type\\\");\",\n\t\t\t\t\t\t\t\t\t\"});\",\n\t\t\t\t\t\t\t\t\t\"\",\n\t\t\t\t\t\t\t\t\t\"/*pm.test(\\\"Response time is less than 200ms\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.expect(pm.response.responseTime).to.be.below(200);\",\n\t\t\t\t\t\t\t\t\t\"});*/\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"POST\",\n\t\t\t\t\t\t\"header\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"key\": \"Content-Type\",\n\t\t\t\t\t\t\t\t\"name\": \"Content-Type\",\n\t\t\t\t\t\t\t\t\"value\": \"application/json\",\n\t\t\t\t\t\t\t\t\"type\": \"text\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"body\": {\n\t\t\t\t\t\t\t\"mode\": \"raw\",\n\t\t\t\t\t\t\t\"raw\": \"{\\\"feature1\\\": 1, \\\"feature2\\\": 1, \\\"feature3\\\": 2}\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/predict?proba=1&explain=1\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"predict\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"query\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"key\": \"proba\",\n\t\t\t\t\t\t\t\t\t\"value\": \"1\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"key\": \"explain\",\n\t\t\t\t\t\t\t\t\t\"value\": \"1\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"Preproces (Example)\",\n\t\t\t\t\t\"event\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"listen\": \"test\",\n\t\t\t\t\t\t\t\"script\": {\n\t\t\t\t\t\t\t\t\"id\": \"ad061700-d459-4ab7-aeb6-9611f64a7218\",\n\t\t\t\t\t\t\t\t\"exec\": [\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Status code is 200\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.status(200);\",\n\t\t\t\t\t\t\t\t\t\"});\",\n\t\t\t\t\t\t\t\t\t\"\",\n\t\t\t\t\t\t\t\t\t\"pm.test(\\\"Content-Type is present\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.response.to.have.header(\\\"Content-Type\\\");\",\n\t\t\t\t\t\t\t\t\t\"});\",\n\t\t\t\t\t\t\t\t\t\"\",\n\t\t\t\t\t\t\t\t\t\"/*pm.test(\\\"Response time is less than 200ms\\\", function () {\",\n\t\t\t\t\t\t\t\t\t\"    pm.expect(pm.response.responseTime).to.be.below(200);\",\n\t\t\t\t\t\t\t\t\t\"});*/\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"type\": \"text/javascript\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"request\": {\n\t\t\t\t\t\t\"method\": \"POST\",\n\t\t\t\t\t\t\"header\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"key\": \"Content-Type\",\n\t\t\t\t\t\t\t\t\"name\": \"Content-Type\",\n\t\t\t\t\t\t\t\t\"value\": \"application/json\",\n\t\t\t\t\t\t\t\t\"type\": \"text\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"body\": {\n\t\t\t\t\t\t\t\"mode\": \"raw\",\n\t\t\t\t\t\t\t\"raw\": \"{\\\"feature1\\\": 1, \\\"feature2\\\": 1, \\\"feature3\\\": 2}\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"url\": {\n\t\t\t\t\t\t\t\"raw\": \"http://localhost:5000/preprocess\",\n\t\t\t\t\t\t\t\"protocol\": \"http\",\n\t\t\t\t\t\t\t\"host\": [\n\t\t\t\t\t\t\t\t\"localhost\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"port\": \"5000\",\n\t\t\t\t\t\t\t\"path\": [\n\t\t\t\t\t\t\t\t\"preprocess\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"response\": []\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t]\n}", ".idea": {}, "workspace.xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"2ca2f523-3809-4276-b10e-1de66f347ef4\" name=\"Changes\" comment=\"\" />\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"ProjectColorInfo\"><![CDATA[{\n  \"associatedIndex\": 3\n}]]></component>\n  <component name=\"ProjectId\" id=\"2p7PZJd86LfvsWHy6H3KRoozL71\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\"><![CDATA[{\n  \"keyToString\": {\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\n    \"last_opened_file_path\": \"/home/alex/Documents/PROJECTS/luncher-api-master\",\n    \"node.js.detected.package.eslint\": \"true\",\n    \"node.js.detected.package.tslint\": \"true\",\n    \"node.js.selected.package.eslint\": \"(autodetect)\",\n    \"node.js.selected.package.tslint\": \"(autodetect)\",\n    \"nodejs_package_manager_path\": \"npm\",\n    \"vue.rearranger.settings.migration\": \"true\"\n  }\n}]]></component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\">\n    <configuration name=\"ml-flask-api-master\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"ml-flask-api-master\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/service.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"2ca2f523-3809-4276-b10e-1de66f347ef4\" name=\"Changes\" comment=\"\" />\n      <created>1732114194487</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1732114194487</updated>\n      <workItem from=\"1732114195538\" duration=\"10041000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/service.py</url>\n          <line>4</line>\n          <option name=\"timeStamp\" value=\"1\" />\n        </line-breakpoint>\n      </breakpoints>\n    </breakpoint-manager>\n  </component>\n</project>", ".gitignore": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a src script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocsrc/_build\ndocs\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# PyCharm\n.idea/\n\n**/node_modules\n**/.ipynb_checkpoints\n**/data\n**/__pycache__\n**/.vscode\n**/env\n\n# Data\n*.joblib\n", "ml-flask-api-master.iml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"PYTHON_MODULE\" version=\"4\">\n  <component name=\"Flask\">\n    <option name=\"enabled\" value=\"true\" />\n  </component>\n  <component name=\"NewModuleRootManager\">\n    <content url=\"file://$MODULE_DIR$\" />\n    <orderEntry type=\"inheritedJdk\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n  </component>\n  <component name=\"PyDocumentationSettings\">\n    <option name=\"format\" value=\"PLAIN\" />\n    <option name=\"myDocStringFormat\" value=\"Plain\" />\n  </component>\n  <component name=\"TemplatesService\">\n    <option name=\"TEMPLATE_CONFIGURATION\" value=\"Jinja2\" />\n  </component>\n</module>", "modules.xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectModuleManager\">\n    <modules>\n      <module fileurl=\"file://$PROJECT_DIR$/.idea/ml-flask-api-master.iml\" filepath=\"$PROJECT_DIR$/.idea/ml-flask-api-master.iml\" />\n    </modules>\n  </component>\n</project>", "inspectionProfiles": {}, "Project_Default.xml": "<component name=\"InspectionProjectProfileManager\">\n  <profile version=\"1.0\">\n    <option name=\"myName\" value=\"Project Default\" />\n    <inspection_tool class=\"DuplicatedCode\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\n      <Languages>\n        <language minSize=\"105\" name=\"Python\" />\n      </Languages>\n    </inspection_tool>\n    <inspection_tool class=\"Eslint\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\" />\n    <inspection_tool class=\"PyPackageRequirementsInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\n      <option name=\"ignoredPackages\">\n        <value>\n          <list size=\"40\">\n            <item index=\"0\" class=\"java.lang.String\" itemvalue=\"cv2\" />\n            <item index=\"1\" class=\"java.lang.String\" itemvalue=\"numpy\" />\n            <item index=\"2\" class=\"java.lang.String\" itemvalue=\"kombu\" />\n            <item index=\"3\" class=\"java.lang.String\" itemvalue=\"sqlalchemy\" />\n            <item index=\"4\" class=\"java.lang.String\" itemvalue=\"kafka\" />\n            <item index=\"5\" class=\"java.lang.String\" itemvalue=\"pydantic\" />\n            <item index=\"6\" class=\"java.lang.String\" itemvalue=\"pytest\" />\n            <item index=\"7\" class=\"java.lang.String\" itemvalue=\"click\" />\n            <item index=\"8\" class=\"java.lang.String\" itemvalue=\"alembic\" />\n            <item index=\"9\" class=\"java.lang.String\" itemvalue=\"pytz\" />\n            <item index=\"10\" class=\"java.lang.String\" itemvalue=\"intervaltree\" />\n            <item index=\"11\" class=\"java.lang.String\" itemvalue=\"falcon\" />\n            <item index=\"12\" class=\"java.lang.String\" itemvalue=\"scikit-learn\" />\n            <item index=\"13\" class=\"java.lang.String\" itemvalue=\"requests-ntlm\" />\n            <item index=\"14\" class=\"java.lang.String\" itemvalue=\"evraz-auto-api\" />\n            <item index=\"15\" class=\"java.lang.String\" itemvalue=\"attrs\" />\n            <item index=\"16\" class=\"java.lang.String\" itemvalue=\"evraz-health-check\" />\n            <item index=\"17\" class=\"java.lang.String\" itemvalue=\"requests\" />\n            <item index=\"18\" class=\"java.lang.String\" itemvalue=\"classic\" />\n            <item index=\"19\" class=\"java.lang.String\" itemvalue=\"psycopg\" />\n            <item index=\"20\" class=\"java.lang.String\" itemvalue=\"python-json-logger\" />\n            <item index=\"21\" class=\"java.lang.String\" itemvalue=\"pypika\" />\n            <item index=\"22\" class=\"java.lang.String\" itemvalue=\"pymssql\" />\n            <item index=\"23\" class=\"java.lang.String\" itemvalue=\"qrcode\" />\n            <item index=\"24\" class=\"java.lang.String\" itemvalue=\"evraz-vault-settings\" />\n            <item index=\"25\" class=\"java.lang.String\" itemvalue=\"python-dotenv\" />\n            <item index=\"26\" class=\"java.lang.String\" itemvalue=\"pyjwt\" />\n            <item index=\"27\" class=\"java.lang.String\" itemvalue=\"evraz-spectree\" />\n            <item index=\"28\" class=\"java.lang.String\" itemvalue=\"minio\" />\n            <item index=\"29\" class=\"java.lang.String\" itemvalue=\"evraz-classic-http-auth\" />\n            <item index=\"30\" class=\"java.lang.String\" itemvalue=\"gunicorn\" />\n            <item index=\"31\" class=\"java.lang.String\" itemvalue=\"spectree\" />\n            <item index=\"32\" class=\"java.lang.String\" itemvalue=\"evraz-classic-http-api\" />\n            <item index=\"33\" class=\"java.lang.String\" itemvalue=\"msgspec\" />\n            <item index=\"34\" class=\"java.lang.String\" itemvalue=\"embrace\" />\n            <item index=\"35\" class=\"java.lang.String\" itemvalue=\"PIL\" />\n            <item index=\"36\" class=\"java.lang.String\" itemvalue=\"watchdog\" />\n            <item index=\"37\" class=\"java.lang.String\" itemvalue=\"psycopg-pool\" />\n            <item index=\"38\" class=\"java.lang.String\" itemvalue=\"psycopg2-binary\" />\n            <item index=\"39\" class=\"java.lang.String\" itemvalue=\"ipcqueue\" />\n          </list>\n        </value>\n      </option>\n    </inspection_tool>\n    <inspection_tool class=\"PyPep8Inspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\n      <option name=\"ignoredErrors\">\n        <list>\n          <option value=\"E501\" />\n        </list>\n      </option>\n    </inspection_tool>\n    <inspection_tool class=\"PyPep8NamingInspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\n      <option name=\"ignoredErrors\">\n        <list>\n          <option value=\"N801\" />\n          <option value=\"N802\" />\n          <option value=\"N803\" />\n        </list>\n      </option>\n    </inspection_tool>\n    <inspection_tool class=\"PyUnresolvedReferencesInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\n      <option name=\"ignoredIdentifiers\">\n        <list>\n          <option value=\"str.like\" />\n        </list>\n      </option>\n    </inspection_tool>\n  </profile>\n</component>", "profiles_settings.xml": "<component name=\"InspectionProjectProfileManager\">\n  <settings>\n    <option name=\"USE_PROJECT_PROFILE\" value=\"false\" />\n    <version value=\"1.0\" />\n  </settings>\n</component>", ".dockerignore": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\ntests/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\ndocsrc/\n.nojekyll\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# PyCharm\n.idea/\n\n**/node_modules\n**/.ipynb_checkpoints\n**/data\n**/__pycache__\n**/.vscode\n**/env\n\n# Setup\nsetup.cfg\n", ".nojekyll": "# TODO: \u043f\u0443\u0441\u0442\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u043d\u0435 \u043f\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0443", "docker-compose.yml": "version: '3'\nservices:\n  flask-ml:\n    container_name: flask-ml\n    build:\n      context: .\n      dockerfile: ./docker/Dockerfile\n    image: flask-ml\n    env_file:\n      - ./docker/.env\n    restart: always\n    ports:\n      - \"5000:5000\"\n", "LICENSE": "MIT License\n\nCopyright (c) 2019 Jos\u00e9 Lopez Colina\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "README.md": "# Flask template for Machine Learning model deployment\n\nA simple example of a Python web service for real time machine learning model deployment.\nIt is based on [this post](https://mikulskibartosz.name/a-comprehensive-guide-to-putting-a-machine-learning-model-in-production-using-flask-docker-and-e3176aa8d1ce)\n\nThis includes Docker integration and SHAP explanations for the deployed model.\n\n[Website](https://lopezco.github.io/ml-flask-api) | [Source](https://github.com/lopezco/ml-flask-api/) | [Issues](https://github.com/lopezco/ml-flask-api/issues)\n\n## Installation\n\n### Requirements  \n\n* [docker](https://docs.docker.com/install/linux/docker-ce/ubuntu/)\n* [docker-compose](https://docs.docker.com/compose/install/) (Recommended)\n\n### Before using\n\nMake sure that you have a model in the main directory.\nYou can launch the example using the following line in order to create a quick\nclassification model.\n```bash\n$ python ./example/build_linear_binary.py\n```\nor one of the scripts in the `./example` folder\n\n### Configuration\n\n* ```variables.env```: Controls API parameters via environment variables\n* ```requirements.txt```: Controls Python packages installed inside the container\n* ```model.joblib```: Model saved inside a dictionary with this format\n\n    ```javascript\n    {\n        \"model\": trained_model,\n        \"metadata\": {\"features\": [\n            {\"name\": \"feature1\", \"type\": \"numeric\", \"accepts_missing\": True},\n            {\"name\": \"feature2\", \"type\": \"numeric\", \"default\": -1, \"accepts_missing\": False},\n            {\"name\": \"feature3\", \"type\": \"category\", \"categories\": [\"A\", \"B\"], \"accepts_missing\": True}]}\n    }\n    ```\n\n## Run the service\n\n### On Docker\n\nBuild the image (this has to be done every time the code or the model changes)\n```bash\n$ docker-compose build\n```\nCreate and run the container\n```bash\n$ docker-compose up\n```\n\n### On local Python environment\n\nCreate the environment\n```bash\n$ conda create -n flask_ml python=3\n$ conda activate flask_ml\n```\nInstall requirements\n```bash\n$ pip install -r ./requirements-service.txt  \n$ pip install -r ./requirements.txt  \n```\nRun the API service\n```bash\n$ python service.py  \n```\n\n## Usage of the API  \n\nThis example considers that the API was launched locally without docker and \nwith the default parameters (`localhost` at port `5000`) and its calling \nthe example model.\n\nFor `/predict` endpoint the JSON string in the payload of hte request can take\ntwo forms:\n\n1. The first, the payload is a record or a list of records with one value\nper feature. This will be directly interpreted as the input for the\nmodel.\n\n2. The second, the payload is a dictionary with 1 or 2 elements. The key\n`_data` is mandatory because this will be the input for the model and\nits format is expected to be a record or a list of records. On the\nother hand, the key `_samples` (optional) will be used to obtain\ndifferent explanations.\n\nIf `_samples` is not given, then the explanations returned are the raw output of\nthe trees, which varies by model (for binary classification in XGBoost\nthis is the log odds ratio). On the contrary, if `_samples` is given,\nthen the explanations are the output of the model transformed into\nprobability space (note that this means the SHAP values now sum to the\nprobability output of the model).\nSee the [SHAP documentation](https://shap.readthedocs.io/en/latest/#shap.TreeExplainer)\nfor details.\n\n### Check the API's health status\n\nEndpoint: `/health`\n\n```bash\n$ curl -X GET http://localhost:5000/health\nup\n```\n\n### Is model ready?\n\nEndpoint: `/ready`\n\n```bash\n$ curl -X GET http://localhost:5000/ready\nready\n```\n\n### Get information about service\n\nEndpoint: `/service-info`\n\n```bash\n$ curl -X GET http://localhost:5000/service-info\n```\n```json\n{\n  \"debug\": true,\n  \"running-since\": 1563355369.6482198,\n  \"serving-model-name\": \"model.joblib\",\n  \"serving-model-type\": \"SKLEARN_MODEL\",\n  \"version-template\": \"2.2.0\"\n}\n```\n\n### Get information about the model\n\nEndpoint: `/info`\n\n```bash\n$ curl -X GET http://localhost:5000/info\n```\n```json\n{\n  \"metadata\": {\n    \"features\": [\n      {\n        \"default\": -1,\n        \"importance\": 0.2,\n        \"name\": \"feature1\",\n        \"type\": \"numeric\"\n      },\n      {\n        \"default\": -1,\n        \"importance\": 0.1,\n        \"name\": \"feature2\",\n        \"type\": \"numeric\"\n      },\n      {\n        \"default\": -1,\n        \"importance\": 0.3,\n        \"name\": \"feature3\",\n        \"type\": \"numeric\"\n      }\n    ]\n  },\n  \"model\": {\n    \"type\": \"<class 'sklearn.ensemble.forest.RandomForestClassifier'>\",\n    \"predictor_type\": \"<class 'sklearn.ensemble.forest.RandomForestClassifier'>\",\n    \"is_explainable\": false,\n    \"task\": \"BINARY_CLASSIFICATION\",\n    \"class_names\": [\"0\", \"1\"]\n  }\n}\n```\n\n### Compute predictions\n\nEndpoint: `/predict`\n\n```bash\n$ curl -d '[{\"feature1\": 1, \"feature2\": 1, \"feature3\": 2}, {\"feature1\": 1, \"feature2\": 1, \"feature3\": 2}]' -H \"Content-Type: application/json\" -X POST http://localhost:5000/predict\n```\n```json\n{\n  \"prediction\": [0, 0]\n}\n```\n\n### Predict probabilities\n\nEndpoint: `/predict?proba=1`\n\n```bash\n$ curl -d '{\"feature1\": 1, \"feature2\": 1, \"feature3\": 2}' -H \"Content-Type: application/json\" -X POST \"http://localhost:5000/predict?proba=1\"\n```\n```json\n{\n  \"prediction\": [{\n    \"0\": 0.8,\n    \"1\": 0.2\n  }]\n}\n```\n\n\n### Get features of the Model with features importances\n\nEndpoint: `/features`\n```bash\n$ curl -X GET \"http://localhost:5000/features\"\n```\n```json\n[\n  {\n    \"default\": -1,\n    \"importance\": 0.2,\n    \"name\": \"feature1\",\n    \"type\": \"numeric\"\n  },\n  {\n    \"default\": -1,\n    \"importance\": 0.1,\n    \"name\": \"feature2\",\n    \"type\": \"numeric\"\n  },\n  {\n    \"default\": -1,\n    \"importance\": 0.3,\n    \"name\": \"feature3\",\n    \"type\": \"numeric\"\n  }\n]\n```\n\n### Get SHAP explanations\n\nEndpoint: `/predict?proba=1&explain=1`\n\n```bash\n$ curl -d '{\"feature1\": 1, \"feature2\": 1, \"feature3\": 2}' -H \"Content-Type: application/json\" -X POST \"http://localhost:5000/predict?proba=1&explain=1\"\n```\n```json\n{\n  \"explanation\": {\n    \"feature1\": 0.10000000149011613,\n    \"feature2\": 0.03333333383003871,\n    \"feature3\": -0.1666666691501935\n  },\n  \"prediction\": [{\n    \"0\": 0.7,\n    \"1\": 0.3\n  }]\n}\n```\n", "requirements-dev.txt": "# Version\nbump2version\n\n# Documentation\nsphinx>=2.1.0\nsphinx_rtd_theme\nm2r\n", "requirements-service.txt": "# Web Service\nflask\ngunicorn\n\n# Model persistance and data handling\nnumpy\njoblib\n\n# Model interpretability\nshap\n", "requirements.txt": "pandas\nnumpy\nscikit-learn\nscipy\nlightgbm\n", "service.py": "#!flask/bin/src\n\"\"\"\nFlask application to serve Machine Learning models\n\"\"\"\nimport os\nimport flask\nimport json\nimport logging\n\nfrom time import time\n\nfrom src.utils.encoder import ExtendedEncoder, returns_json\nfrom src.factory import ModelFactory\n# TODO: \u041c\u043e\u043d\u043e\u043b\u0438\u0442, \u0432\u0441\u0435 \u0432 \u043e\u0434\u043d\u043e\u043c \u043c\u0435\u0441\u0442\u0435, \u043b\u043e\u0433\u0438\u043a\u0430, \u0442\u043e\u0447\u043a\u0430 \u0432\u0445\u043e\u0434\u0430, \u0440\u043e\u0443\u0442\u0438\u043d\u0433 ...\n\n# Version of this APP template\n__version__ = '2.2.0'\n# Read env variables\nDEBUG = os.environ.get('DEBUG', False)\nMODEL_NAME = os.environ.get('MODEL_NAME', 'model.joblib')\nENVIRONMENT = os.environ.get('ENVIRONMENT', 'local')\nMODEL_TYPE = os.environ.get('MODEL_TYPE', 'SKLEARN_MODEL')\nSERVICE_START_TIMESTAMP = time()\n# Create Flask Application\napplication = flask.Flask(__name__)\n# Customize Flask Application\napplication.logger.setLevel(logging.DEBUG if DEBUG else logging.ERROR)\napplication.json_encoder = ExtendedEncoder\n# Create Model instance\nmodel = ModelFactory.create_model(MODEL_NAME, MODEL_TYPE)\n# load saved model\napplication.logger.info('ENVIRONMENT: {}'.format(ENVIRONMENT))\napplication.logger.info('Using template version: {}'.format(__version__))\napplication.logger.info('Loading model...')\nmodel.load()\n\n\n@application.route('/predict', methods=['POST'])\n@returns_json\ndef predict():\n    \"\"\"Make preditcions and explain them\n\n    Model inference using input data. This is the main function.\n\n    URL Params:\n        proba (int):\n            1 in order to compute probabilities for classification models or 0\n            to return predicted class (classification) or value (regression).\n            Default 0.\n        explain (int):\n            1 in order to compute moeldel explanations for the predicted value.\n            This will return a status 500 when the model does not support\n            explanations. Default 0.\n\n    Payload:\n        JSON string that can take two forms:\n\n        The first, the payload is a record or a list of records with one value\n        per feature. This will be directly interpreted as the input for the\n        model.\n\n        The second, the payload is a dictionary with 1 or 2 elements. The key\n        \"_data\" is mandatory because this will be the input for the model and\n        its format is expected to be a record or a list of records. On the\n        other hand the key \"_samples\" (optional) will be used to obtain\n        different explanations (see :func:`~model.Model.explain`)\n    \"\"\"\n    # Parameters\n    do_proba = int(flask.request.args.get('proba', 0))\n    do_explain = int(flask.request.args.get('explain', 0))\n    input = json.loads(flask.request.data or '{}')\n    if isinstance(input, dict):\n        samples = input.get('_samples', None)\n        data = input.get('_data', {})\n        if len(data.items()):\n            input = data\n    else:\n        samples = None\n    # Predict\n    before_time = time()\n    try:\n        predict_function = 'predict_proba' if do_proba else 'predict'\n        prediction = getattr(model, predict_function)(input)\n    except Exception as err:\n        return flask.Response(str(err), status=500)\n    result = {'prediction': prediction}\n    # Explain\n    if do_explain:\n        try:\n            explanation = model.explain(input, samples=samples)\n        except Exception as err:\n            return flask.Response(str(err), status=500)\n        else:\n            result['explanation'] = explanation\n    after_time = time()\n    # log\n    to_be_logged = {\n        'input': flask.request.data,\n        'params': flask.request.args,\n        'request_id': flask.request.headers.get('X-Correlation-ID'),\n        'result': result,\n        'model_info': model.info,\n        'elapsed_time': after_time - before_time\n    }\n    application.logger.debug(to_be_logged)\n    return result\n\n\n@application.route('/info', methods=['GET'])\n@returns_json\ndef info():\n    \"\"\"Model information\n\n    Get the model information: metadata, type, classifier, etc.\n\n    \"\"\"\n    try:\n        info = model.info\n    except Exception as err:\n        return flask.Response(str(err), status=500)\n    else:\n        return info\n\n\n@application.route('/features', methods=['GET'])\n@returns_json\ndef features():\n    \"\"\"Model features\n\n    Get the model accepted features. This includes feature inportance if the\n    model allows it.\n\n    \"\"\"\n    try:\n        features = model.features()\n    except Exception as err:\n        return flask.Response(str(err), status=500)\n    else:\n        return features\n\n\n@application.route('/preprocess', methods=['POST'])\n@returns_json\ndef preprocess():\n    \"\"\"Preporcess input data\n\n    Get the preprocessed version of the input data. If the model does not\n    include preprocessing steps, this method will return the same data as the\n    input.\n\n    \"\"\"\n    input = json.loads(flask.request.data or '{}')\n    try:\n        data = model.preprocess(input)\n    except Exception as err:\n        return flask.Response(str(err), status=500)\n    else:\n        return data\n\n\n@application.route('/health')\ndef health_check():\n    return flask.Response(\"up\", status=200)\n\n\n@application.route('/ready')\ndef readiness_check():\n    if model.is_ready():\n        return flask.Response(\"ready\", status=200)\n    else:\n        return flask.Response(\"not ready\", status=503)\n\n\n@application.route('/service-info')\n@returns_json\ndef service_info():\n    \"\"\"Service information\n\n    Get information about the service: up-time, varsion of the template, name\n    of the served model, etc.\n\n    \"\"\"\n    info = {\n        'version-template': __version__,\n        'running-since': SERVICE_START_TIMESTAMP,\n        'serving-model-file': MODEL_NAME,\n        'serving-model-family': model.family,\n        'debug': DEBUG\n    }\n    return info\n\n\nif __name__ == '__main__':\n    application.run(\n        debug=DEBUG,\n        host=os.environ.get('HOST', 'localhost'),\n        port=os.environ.get('PORT', '5000'))\n", "setup.cfg": "[bumpversion]\ncurrent_version = 2.2.0\ncommit = True\ntag = True\n\n[bumpversion:file:service.py]\nparse = (?P<major>\\d+)\\.(?P<minor>\\d+)\\.(?P<patch>\\d+)\n\n[bumpversion:file:README.md]\nparse = (?P<major>\\d+)\\.(?P<minor>\\d+)\\.(?P<patch>\\d+)\n\n[bumpversion:file:docsrc/source/conf.py]\nparse = (?P<major>\\d+)\\.(?P<minor>\\d+)\\.(?P<patch>\\d+)\n\n", "review.md": "1. \u041e\u0442\u0441\u0443\u0442\u0441\u0432\u0443\u0435\u0442 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0438\u0430\u0433\u0440\u0430\u043c\u043c\u044b \u0411\u0414, \u0434\u0435\u043f\u043b\u043e\u0439\u043c\u0435\u043d\u0442\u0430\n2. O\u0442\u0441\u0443\u0442\u0441\u0432\u0443\u0435\u0442 \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f  deployment, \u043d\u0435 \u043f\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0430\u043c \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438\n3. \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u043e\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043a \u043a\u0430\u043a\u043e\u0439 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u043f\u0440\u043e\u0435\u043a\u0442, \u043f\u043b\u043e\u0445\u043e \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u043f\u0440\u043e\u0435\u043a\u0442\n4. \u041e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043f\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0443\n5. \u041b\u043e\u0433\u0438\u043a\u0430, \u0442\u043e\u0447\u043a\u0430 \u0432\u0445\u043e\u0434\u0430, \u0440\u043e\u0443\u0442\u0438\u043d\u0433 \u0432\u0441\u0435 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043e\u0434\u043d\u043e\u043c \u043c\u043e\u0434\u0443\u043b\u0435, \u043c\u043e\u043d\u043e\u043b\u0438\u0442\n\n\u041e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u043b \u043f\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0443 \u0432 TODO: \"\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0439\"\n"}